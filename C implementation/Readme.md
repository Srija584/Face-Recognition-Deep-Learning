1. First, cnn_weights.c generate models for non-frontal to frontal conversions for each person in the database.

2. Next, cnn_prediction.c takes an input test image and use all models generated by cnn_weights.c to generatefrontal image from it.

3. Finally, predictCount.m uses all those generated images from all test images to givefinal count of correctly predicted images.


Note - cnn_weights.c needs to be run only once to generate models.
        cnn_prediction.c needs to be run for all test images. I have grouped test images according to the head pose 
        and used temp.py file to generate frontal images from test images in one pose group in one go and then predictCount.m for that pose 
        group. In the paper also, the accuracy is given group wise(according to head pose).
